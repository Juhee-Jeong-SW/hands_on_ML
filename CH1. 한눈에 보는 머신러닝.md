## 1.5 머신러닝 주요 도전 과제

머신러닝 : 학습 알고리즘 선택 후 데이터를 훈련시키는 것.

여기서 문제가 될 수 있는 부분은 "알고리즘"과 "데이터"

- 데이터 문제
  1. 충분하지 않은 양의 훈련 데이터
  2. 대표성 없는 훈련 데이터
  3. 낮은 품질의 데이터
  4. 관련 없는 특성
- 알고리즘 문제
  1. 훈련 데이터 과대적합
  2. 훈련 데이터 과소적합

### 1.5.1 충분하지 않은 양의 훈련 데이터

- 간단한 문제라도 수천 개의 데이터가 필요 ( 특히 이미지, 음석 같은 경우 수백만 개가 필요할 수도)

- 데이터가 충분하면 알고리즘 성능을 크게 높일 수 있지만,

- 부족하면 알고리즘 개선에 방해가 됨.

  ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/19d09cfe-7c53-4650-8875-55d4a9a8c8cc/_2020-12-26__4.56.49.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/19d09cfe-7c53-4650-8875-55d4a9a8c8cc/_2020-12-26__4.56.49.png)

### 1.5.2 대표성 없는 훈련 데이터

- 새로운 사례를 모델이 잘 대표하는 것이 중요함 → 일반화의 중요성
- 샘플 작으면 발생, 샘플링 잡음 : 우연에 의해 대표성이 없는 데이터
- 큰 샘플에서도 발생 가능, 샘플링 편향 : 표본 추출 방법이 잘못된 대표성이 없는 데이터
- 예 : 미국 대통령 선거 랜던과 루즈벨트 (예상 : 랜던 승 but 실제 : 루즈벨트 승)
  - 원인 : 명부 자체가 공화당에 투표할 가능성이 높은 계층에 편향되었음/ 정치에 관심없는 사람에 대한 응답은 포함시키지 않음.

** 일반화란? 테스트 데이터에 대한 높은 성능을 갖추는 것

### 1.5.3 낮은 품질의 데이터

- 낮은 품질의 데이터란 : 에러, 이상치, 잡음이 많은 것.
- 훈련 데이터 정제 필요
- 이상치 샘플일 경우 고치거나 무시
- 특성 누락시
  - 무시할지 ( 샘플, or 특성을 제외)
  - 누락된 값 채울지 ( 예를 들면 평균 )
  - 특성을 넣은 경우와 뺀 경우를 포함하여 각기 모델을 훈련할지 정해야 함.

### 1.5.4 관련 없는 특성

- input 이 잘못되면 output도 어긋날 가능성 큼 → 훈련에 사용할 좋은 특성들을 찾는 것이 중요.
- 특성 공학 : 풀려는 문제와 관련이 높은 특성을 찾는 것.
  - 특성 선택 : 가지고 있는 특성 중 훈련에 가장 유용한 특성 선택
  - 특성 추출 : 특성을 결합해 더 유용한 특성 만들기

여기까지 데이터 관련, 뒤로부터는 알고리즘 관련

### 1.5.5 훈련 데이터 과대적합

- 머신러닝

  - 훈련 데이터를 활용해서 실전에도 익히는 것이 중요.
  - 훈련데이터 최적화와 실전에서의 일반화 둘 사이의 올바른 밸런스 필요

- 과대 적합이란? 훈련 세트에 너무 잘 맞은 나머지 일반화 성능이 낮은 현상

  → 훈련 데이터에 치중한 나머지 모델이 복잡해지는 현상. 정확도는 높으나 실전에 사용하기에 현명하지 않음.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/45b9ef2e-c42b-4f5a-ac47-24dc620a0368/_2020-12-26__5.15.07.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/45b9ef2e-c42b-4f5a-ac47-24dc620a0368/_2020-12-26__5.15.07.png)

- 해결방법 → 규제 : 모델을 단순하게 하고 과대적합의 위험을 감수시키기 위해 모델에 제약을 가하는 것.
- 하이퍼파라미터 : 알고리즘을 조절하기 위해 사전에 정의하는 파라미터. /
  - 학습 알고리즘으로부터 영향 받지 않음.
  - 훈련 전에 미리 지정되어 있음.
  - 훈련하는 동안에는 상수로 존재함.
- 규제 하이퍼 파라미터를 큰 값으로 지정할수록 복잡도가 낮은 모델을 얻게됨.
- 반대로 너무 높이면 과소적합 발생할 수 있음.
- 적절히 조절할 것!

### 1.5.6 훈련 데이터 과소적합

- 과대적합의 반대

- 모델이 너무 단순해서 훈련 세트를 잘 학습하지 못함.

- Ex) 삶의 만족도 선형 모델 : 삶은 더 복잡하므로 훈련 샘프에서조차 부정확한 예측 만들 가능성이 높음.

- 해결방법

  → 모델 파라미터가 더 많은 강력한 모델을 사용한다.

  → 특성 공학으로 더 좋은 특성을 찾는다.

  → 규제 강도를 줄인다.

------

## 1.6 테스트와 검증

- 모델의 일반화 성능을 측정하기 위해 훈련세트와 테스트 세트로 나눠 측정.

  - 훈련 세트 : 모델 훈련
  - 테스트 세트 : 모델 테스트

- 일반화 오차 : 새로운 샘플에 대한 오류 비율

  - 테스트 세트에서 평가함으로써 오차에 대한 추정값을 얻음.
  - 새로운 샘플에 모델이 잘 작동하는가에 대한 척도

- 훈련 오차 낮지만, 일반화 오차 높다면

  → 모델이 훈련데이터에 과대적합.

### 1.6.1 하이퍼파라미터 튜닝과 모델 선택

- 모델을 평가하고 선택하기 : 훈련 세트로 훈련한 뒤 테스트 세트 사용하여 일반화 평가

  ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b2a3efcb-1d64-4295-9be6-4cfbc2733aa8/_2020-12-26__6.11.20.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b2a3efcb-1d64-4295-9be6-4cfbc2733aa8/_2020-12-26__6.11.20.png)

- 규제 적용을 위한 하이퍼파라미터 값 선택 : 100개의 하이퍼 파라미터 , 100개의 다른 모델 훈련 → 이 중 일반화 오차가 낮은 최적의 하이퍼 파라미터를 찾아 투입 → 문제 발생

- 테스트 세트에 최적화된 모델을 만들었음. 즉, 테스트에만 적합한 모델이 되도록 테스트한 것. 그래서 새로운 모델에 유연하게 작동하기 어려움.

- 해결방법 : 홀드아웃 검증

  → 훈련세트 일부를 떼어내 여러 후보 모델 평가 후 가장 좋은 것 선택 (검증세트)

  → 전체 훈련 세트 중 검증 세트를 뺀 훈련 세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련한 뒤, 검증 세트에서 가장 높은 성능을 내는 모델을 선택한다!

  ** 훈련세트와 검증세트의 분리

  ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3c71d36d-2b24-4fb2-8da6-3ea5f13760c0/_2020-12-26__6.11.50.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3c71d36d-2b24-4fb2-8da6-3ea5f13760c0/_2020-12-26__6.11.50.png)

  - 문제점1 : 검증 세트가 너무 작으면 모델이 정확하게 평가되기 어려움. (최적화되지 않은 모델을 잘못 선택할 수도)

  - 문제점2 : 검증세트가 너무 크면 남은 훈련 세트가 전체 훈련 세트보다 너무 작아지게 됨.

    - 해결방법 : 교차 검증

    → 여러 검증 세트를 구성하고, 각 검증 세트마다 나머지 데이터로 훈련 후 검증 세트로 평가

    → 모든 모델의 평가를 평균하여 성능 측정

    → But, 검증 세트의 개수에 비례하므로 훈련 시간 증가 문제 발생

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ef8a642d-11de-478f-9d3b-0a386535c358/_2020-12-26__6.12.21.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ef8a642d-11de-478f-9d3b-0a386535c358/_2020-12-26__6.12.21.png)

- 데이터 불일치

  많은 양의 데이터가 실제 제품에 사용될 데이터를 완벽하게 대표하지 못할 수도 있음.

  ex) 앱으로 찍은 꽃사진은 웹에서 찾은 사진으로 대표하기 어렵다.

  검증 세트와 테스트 세트에 앱으로 찍은 사진을 반반 포함시켜야 한다.

  검증 세트로 모델을 평가할 경우 성능이 낮으면 두가지 의심

  1. 훈련 세트에 과대적합 되었음.
  2. 훈련 세트와의 데이터가 불일치함.

  "훈련 개발 세트"로 해결

  - 웹 사진 중 일부를 따로 떼어 내어 '훈련 개발 세트'를 만든 뒤, 웹 사진이 없는 훈련 세트로 훈련한 후에 평가한다.
  - 훈련 개발 세트가 OK → 검증 세트에서 나쁜 성능 = 데이터 불일치 → 데이터를 전처리하여 다시 훈련 필요
  - 훈련 개발 세트가 BAD → 훈련 세트에 과대 적합.